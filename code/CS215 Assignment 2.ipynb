{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CS215 Assignment 2\n",
    "### 210010076 Shantanu Welling\n",
    "### 210050044 Dhananjay Raman"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importing all relevant libraries and defining constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.stats as stats\n",
    "import h5py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Set random seed\n",
    "np.random.seed(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Q1 (b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "theta=np.random.uniform(size=10000000) #Sample 10^7 points between 0 and 1\n",
    "theta*=2*np.pi #Map them to 0 to 2*pi, they represent the polar angle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "r=np.random.uniform(size=10000000) \n",
    "#Sample 10^7 points between 0 & 1, representing \n",
    "#r in polar co-ordinates\n",
    "r=np.sqrt(r) #Use CDF inverse method for sqrt(r) as mentioned in the algorithm\n",
    "x=[]\n",
    "y=[]\n",
    "for i in range(len(r)):\n",
    "    x.append(r[i]*np.cos(theta[i])) #append x co-ordinate, already set to scale\n",
    "    y.append(r[i]*np.sin(theta[i])*0.5) \n",
    "    #append y co-ordinate and scale it to minor axis length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist2d(x,y,bins=500,density=True,cmap=plt.cm.Reds)\n",
    "plt.colorbar()\n",
    "plt.gca().set_aspect('equal', adjustable='box')\n",
    "plt.title(\"Ellipse Sample Points Histogram\")\n",
    "plt.xlabel(\"X axis\")\n",
    "plt.ylabel(\"Y axis\")\n",
    "plt.savefig(\"../results/ellipse_hist.jpg\", dpi=600)\n",
    "plt.close();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Q1 (c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "u=np.random.uniform(size=10000000) #Generate 10^7 uniform random numbers betwen 0 & 1\n",
    "v=np.random.uniform(size=10000000) #To scale the 2 side length vectors\n",
    "resx=[] #Result x co-ordinates\n",
    "resy=[] #Result y co-ordinates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "side1=((np.pi/3)**2+(np.e)**2)**(0.5) #Length of side between (0,0) and (pi/3,e)\n",
    "side2=np.pi #Length of side along x axis\n",
    "ang1=np.arctan(np.e*3/np.pi) #Angle between the 2 sides"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(u)):\n",
    "    if(u[i]+v[i]<=1): #If sum of 2 scaled side length vectors lies in the triangle\n",
    "        resx.append(v[i]*side2+u[i]*side1*np.cos(ang1)) \n",
    "        resy.append(u[i]*side1*np.sin(ang1))\n",
    "        #Append the x & y co-ordinates of the 2 summed vectors\n",
    "    else: \n",
    "        #If sum of 2 scaled side length vectors lies in the other half of the\n",
    "        #parallelogram spanned by the 2 side vectors, reflect it along the \n",
    "        #parallelogram diagonal\n",
    "        resx.append((1-v[i])*side2+ (1-u[i])*side1*np.cos(ang1))\n",
    "        resy.append((1-u[i])*side1*np.sin(ang1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist2d(resx,resy,bins=500,density=True, cmap=plt.cm.Reds)\n",
    "plt.colorbar()\n",
    "plt.title(\"Triangle Sample Points Histogram\")\n",
    "plt.xlabel(\"X axis\")\n",
    "plt.ylabel(\"Y axis\")\n",
    "plt.savefig(\"../results/triangle_hist.jpg\", dpi=600)\n",
    "plt.close();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Q2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "C=np.array([[1.6250,-1.9486],[-1.9486,3.8750]]) #Covariance matrix\n",
    "mu=np.array([1,2]) #Mean matrix\n",
    "nlist=[10,100,1000,10000,100000] #List of Ns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "evalues,evecs=np.linalg.eig(C) #Compute eigenvalues of Covariance matric\n",
    "diagmat = np.array([[evalues[0],0],[0,evalues[1]]]) #Compute Diagonal Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "A = np.matmul(evecs,diagmat**0.5); #Using C=AA^T, compute A \n",
    "# C = QDQ^T (Since C is real symmetric)\n",
    "# Where Q (orthogonal) is matrix of eigenvectors of C\n",
    "# D is diagonal matrix of eigen values of C\n",
    "# C = (QD^(1/2))(QD^(1/2))^T = AA^T\n",
    "# A = QD^(1/2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "xlist=[] #List of all points for all Ns\n",
    "for n in nlist:\n",
    "    Xnlist=np.zeros(shape=(2,n)) #List of points generated for a given N\n",
    "    for i in range(n):\n",
    "        w1=np.random.normal()\n",
    "        w2=np.random.normal()\n",
    "        W=np.array([w1,w2])\n",
    "        X=np.matmul(A,np.transpose(W))+np.transpose(mu) #X=AW+u\n",
    "        Xnlist[:,i]=X\n",
    "    xlist.append(Xnlist) #Append N points list to final list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "xmeans=[] #MLE Mean for all Ns\n",
    "xcovs=[] #MLE Covariance for all Ns\n",
    "for i in range(len(xlist)):\n",
    "    xmeans.append(np.sum(xlist[i], axis=1)/len(xlist[i][0])) #Sum all the points for a given N and divide by N\n",
    "    covar=np.zeros(shape=(len(xlist[i]),len(xlist[i])))\n",
    "    l=len(xlist[i][0])\n",
    "    for j in range(len(xlist[i])):\n",
    "        for k in range(len(xlist[i])): #Compute Covariance\n",
    "            covar[j,k]=np.sum(xlist[i][j,:]*xlist[i][k,:])/l-np.sum(xlist[i][j,:])*np.sum(xlist[i][k,:])/l**2\n",
    "    xcovs.append(covar) #Append computed covariance matrix to the list\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q2 (b) & (c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "means=np.zeros(shape=(5,100)) #List for errors in mean\n",
    "covarerr=np.zeros(shape=(5,100)) #List for errors in Covariance matrix\n",
    "Cnorm=np.linalg.norm(C, 'fro') #Norm of Covariance matrix\n",
    "for t in range(100): #For each N repeeating experiment 100 times\n",
    "    xlist=[]\n",
    "    for n in nlist: #compute mean as above\n",
    "        Xnlist=np.zeros(shape=(2,n))\n",
    "        for i in range(n):\n",
    "            w1=np.random.normal()\n",
    "            w2=np.random.normal()\n",
    "            W=np.array([w1,w2])\n",
    "            X=np.matmul(A,np.transpose(W))+np.transpose(mu)\n",
    "            Xnlist[:,i]=X\n",
    "        xlist.append(Xnlist)\n",
    "    for i in range(len(xlist)):\n",
    "        m=np.sum(xlist[i], axis=1)/len(xlist[i][0])\n",
    "        meanerror=np.linalg.norm(m-np.transpose(mu))/np.linalg.norm(np.transpose(mu)) #find error in mean\n",
    "        means[i][t]=meanerror #append error in mean to the mean error list\n",
    "        covar=np.zeros(shape=(len(xlist[i]),len(xlist[i]))) \n",
    "        l=len(xlist[i][0])\n",
    "        for j in range(len(xlist[i])): #compute covariance matrix as above\n",
    "            for k in range(len(xlist[i])):\n",
    "                covar[j,k]=np.sum(xlist[i][j,:]*xlist[i][k,:])/l-np.sum(xlist[i][j,:])*np.sum(xlist[i][k,:])/l**2\n",
    "        covarerr[i][t]=np.linalg.norm(covar-C, 'fro')/Cnorm #append error in covariance matrix to the corresponding list\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Boxplot for errors in Mean\n",
    "data=[] \n",
    "for i in range(len(means)):\n",
    "    data.append(means[i,:])\n",
    "plt.boxplot(data);\n",
    "plt.xlabel(\"$log_{10}N$\")\n",
    "plt.xticks(ticks=[1,2,3,4,5], labels=[1,2,3,4,5])\n",
    "plt.title('Boxplot (Bivariate Gaussian Distribution)')\n",
    "plt.ylabel('Standardized Error in Mean')\n",
    "plt.savefig('../results/boxplot_bivariate_gauss_mean.jpg',dpi=600)\n",
    "plt.close();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Boxplot for errors in Covariance matrix\n",
    "data2=[]\n",
    "for i in range(len(covarerr)):\n",
    "    data2.append(covarerr[i,:])\n",
    "plt.boxplot(data2);\n",
    "plt.xlabel(\"$log_{10}N$\")\n",
    "plt.xticks(ticks=[1,2,3,4,5], labels=[1,2,3,4,5])\n",
    "plt.title('Boxplot (Bivariate Gaussian Distribution)')\n",
    "plt.ylabel('Standardized Error in Covariance')\n",
    "plt.savefig('../results/boxplot_bivariate_gauss_covar.jpg',dpi=600)\n",
    "plt.close();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q2 (d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "xlist=[] #Computation logic same as Q2 (b) & (c)\n",
    "for n in nlist:\n",
    "    Xnlist=np.zeros(shape=(2,n))\n",
    "    for i in range(n):\n",
    "        w1=np.random.normal()\n",
    "        w2=np.random.normal()\n",
    "        W=np.array([w1,w2])\n",
    "        X=np.matmul(A,np.transpose(W))+np.transpose(mu)\n",
    "        Xnlist[:,i]=X\n",
    "    xlist.append(Xnlist)\n",
    "xmeans=[]\n",
    "xcovs=[]\n",
    "for i in range(len(xlist)):\n",
    "    xmeans.append(np.sum(xlist[i], axis=1)/len(xlist[i][0]))\n",
    "    covar=np.zeros(shape=(len(xlist[i]),len(xlist[i])))\n",
    "    l=len(xlist[i][0])\n",
    "    for j in range(len(xlist[i])):\n",
    "        for k in range(len(xlist[i])):\n",
    "            covar[j,k]=np.sum(xlist[i][j,:]*xlist[i][k,:])/l-np.sum(xlist[i][j,:])*np.sum(xlist[i][k,:])/l**2\n",
    "    xcovs.append(covar)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(3,2, figsize=(10,20)) #subplots\n",
    "fig.suptitle('Scatter Plots',size=20) #Scatter plots for each N of a single data sample\n",
    "for i in range(len(xlist)):\n",
    "    covar = xcovs[i]\n",
    "    m = xmeans[i]\n",
    "    evalues,evecs=np.linalg.eig(covar) #Computing eigenvalues and eigenvectors\n",
    "    ax[i//2][i%2].scatter(xlist[i][0,:],xlist[i][1,:])\n",
    "    #Plotting principal modes of variation\n",
    "    ax[i//2][i%2].plot((m[0],m[0]+evecs[0][0]*np.sqrt(evalues[0])),(m[1],m[1]+evecs[1][0]*np.sqrt(evalues[0])),'k-',lw=3)\n",
    "    ax[i//2][i%2].plot((m[0],m[0]+evecs[0][1]*np.sqrt(evalues[1])),(m[1],m[1]+evecs[1][1]*np.sqrt(evalues[1])),'r-',lw=3)\n",
    "    ax[i//2][i%2].set_title(f\"N = {nlist[i]}\")\n",
    "    ax[i//2][i%2].set_xlabel('X',size=12)\n",
    "    ax[i//2][i%2].set_ylabel('Y',size=12)\n",
    "    ax[i//2][i%2].set_aspect('equal', adjustable='box')\n",
    "fig.delaxes(ax[2][1])\n",
    "fig.savefig(\"../results/scatter_bivariate.jpg\",dpi=800);\n",
    "plt.close();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "arrays={}\n",
    "mat = h5py.File('../data/points2D_Set1.mat')\n",
    "for k, v in mat.items():\n",
    "    arrays[k] = np.array(v)\n",
    "points = np.array([np.array(arrays['x']),np.array(arrays['y'])])\n",
    "points = points[:,0,:]\n",
    "covar = np.zeros(shape=(2,2)) #Compute covariance matrix for sample points\n",
    "for i in range(2):\n",
    "    for j in range(2):\n",
    "        l=len(points[0])\n",
    "        covar[i][j]=np.sum(points[i,:]*points[j,:])/l - np.sum(points[i,:])*np.sum(points[j,:])/l**2\n",
    "evalues,evecs=np.linalg.eig(covar) #Compute eigenvectors and eigenvalues\n",
    "#Principal mode of variation is along the eigenvector having maximum eigenvalue\n",
    "#Linear relationship between X and Y can be approximated by the direction of their principal mode\n",
    "# of variation\n",
    "if evalues[0]>evalues[1]:\n",
    "    dirn = evecs[:,0]\n",
    "else:\n",
    "    dirn = evecs[:,1]\n",
    "mu = np.sum(points,axis=1)/len(points[0]) #Mean of the sample set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(arrays['x'], arrays['y']) #Scatter plot of the dataset\n",
    "#Line approximating linear relationship between the points\n",
    "plt.plot((np.min(points[0,:]),np.max(points[0,:])),(mu[1]+(np.min(points[0,:])-mu[0])*dirn[1]/dirn[0],mu[1]+(np.max(points[0,:])-mu[0])*dirn[1]/dirn[0]),'r-',lw=2)\n",
    "plt.xlabel(\"X axis\")\n",
    "plt.ylabel(\"Y axis\")\n",
    "plt.title(\"Scatter plot Set 1\")\n",
    "plt.savefig(\"../results/scatterplot_set1.jpg\",dpi=600)\n",
    "plt.close();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Second part same as above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "arrays={}\n",
    "mat = h5py.File('../data/points2D_Set2.mat')\n",
    "for k, v in mat.items():\n",
    "    arrays[k] = np.array(v)\n",
    "points = np.array([np.array(arrays['x']),np.array(arrays['y'])])\n",
    "points = points[:,0,:]\n",
    "covar = np.zeros(shape=(2,2))\n",
    "for i in range(2):\n",
    "    for j in range(2):\n",
    "        l=len(points[0])\n",
    "        covar[i][j]=np.sum(points[i,:]*points[j,:])/l - np.sum(points[i,:])*np.sum(points[j,:])/l**2\n",
    "evalues,evecs=np.linalg.eig(covar)\n",
    "if evalues[0]>evalues[1]:\n",
    "    dirn = evecs[:,0]\n",
    "else:\n",
    "    dirn = evecs[:,1]\n",
    "mu = np.sum(points,axis=1)/len(points[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(arrays['x'], arrays['y'])\n",
    "plt.plot((np.min(points[0,:]),np.max(points[0,:])),(mu[1]+(np.min(points[0,:])-mu[0])*dirn[1]/dirn[0],mu[1]+(np.max(points[0,:])-mu[0])*dirn[1]/dirn[0]),'r-',lw=2)\n",
    "plt.xlabel(\"X axis\")\n",
    "plt.ylabel(\"Y axis\")\n",
    "plt.title(\"Scatter plot Set 2\")\n",
    "plt.savefig(\"../results/scatterplot_set2.jpg\",dpi=600)\n",
    "plt.close();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "arrays={}\n",
    "mat = h5py.File('../data/mnist.mat') #Load and process data\n",
    "for k, v in mat.items():\n",
    "    arrays[k] = np.array(v, dtype=np.float64)\n",
    "for i in range(len(arrays['digits_train'])):\n",
    "    arrays['digits_train'][i]=np.transpose(arrays['digits_train'][i])\n",
    "for i in range(len(arrays['digits_test'])):\n",
    "    arrays['digits_test'][i]=np.transpose(arrays['digits_test'][i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Q4 (i): Mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "digits=[i for i in range(10)] \n",
    "meanmat={key: np.zeros((28**2,1)) for key in digits} #Dictionary mapping each digit to its mean vector\n",
    "sizemat={key: 0 for key in digits} #Dictionary mapping each digit to number of data samples of that digit\n",
    "\n",
    "for i in range(len(arrays['digits_train'])):\n",
    "    meanmat[arrays['labels_train'][0][i]]+=np.reshape(arrays['digits_train'][i],(28**2,1)) #Compute mean\n",
    "    sizemat[arrays['labels_train'][0][i]]+=1 #Increment size\n",
    "for key1 in sizemat.keys():\n",
    "    meanmat[key1]/=sizemat[key1] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(3,4, figsize=(10,8)) #subplots\n",
    "fig.suptitle(\"Mean Matrices of Digits\") #Plot mean of digits\n",
    "for key1 in meanmat.keys():\n",
    "    ax[key1//4][key1%4].imshow(np.reshape(meanmat[key1],(28,28)))\n",
    "fig.delaxes(ax[2][2])\n",
    "fig.delaxes(ax[2][3])\n",
    "plt.savefig(\"../results/digitsmean.jpg\",dpi=600)\n",
    "plt.close();\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Q4 (ii) Covariance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "covmat={key: np.zeros((28**2,28**2)) for key in digits} #Dictionary mapping digits to their covariance matrix\n",
    "for i in range(len(arrays['digits_train'])):\n",
    "    covmat[arrays['labels_train'][0][i]]+=np.matmul(np.reshape(arrays['digits_train'][i],(28**2,1)),np.transpose(np.reshape(arrays['digits_train'][i],(28**2,1))))\n",
    "for key1 in covmat.keys():\n",
    "    covmat[key1]/=(sizemat[key1]-1) #(n-1) as sample covariance\n",
    "    covmat[key1]-=np.matmul(meanmat[key1],np.transpose(meanmat[key1])) #Compute covariance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "eiglist={key: 0 for key in digits} #Dictionary mapping digits to their eigenvalues\n",
    "for key1 in digits:\n",
    "    eiglist[key1]=np.sort(np.linalg.eigvalsh(covmat[key1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Principal mode of variation of each digit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "eigval_principal={key: 0 for key in digits} #Principal eigenvalue for each digit\n",
    "eigvecs_principal={key: None for key in digits} #Principal eigenvector for each digit\n",
    "for k in covmat.keys():\n",
    "    eigv,eigvecs=np.linalg.eigh(covmat[k])\n",
    "    eigval_principal[k]= np.max(eigv)\n",
    "    indmax=np.argmax(eigv)\n",
    "    eigvecs_principal[k]=np.reshape(eigvecs[:,indmax],(28**2,1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Graph of eigenvalues for each digit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "xs=[i for i in range(1,28**2+1)]\n",
    "fig,ax=plt.subplots(4,3,figsize=(23,23))\n",
    "for key1 in eiglist.keys():\n",
    "    ax[key1//3][key1%3].plot(xs,np.flip(eiglist[key1]), 'b.')\n",
    "    ax[key1//3][key1%3].set_ylabel(\"Eigenvalues\")\n",
    "    ax[key1//3][key1%3].set_xlabel(\"Index of eigenvalue\")\n",
    "    ax[key1//3][key1%3].set_title(f\"Digit {key1}\")\n",
    "fig.delaxes(ax[3][1])\n",
    "fig.delaxes(ax[3][2])\n",
    "plt.savefig(\"../results/digits_eigvals.jpg\",dpi=400)\n",
    "plt.close();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Principal mode of variation of digits around their mean and their plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig,ax=plt.subplots(3,3,figsize=(12,12))\n",
    "for key1 in range(3):\n",
    "    eigv,eigvect=np.linalg.eigh(covmat[key1])\n",
    "    maxind=np.argmax(eigv)\n",
    "    maxeigvec=eigvect[:,maxind]\n",
    "    maxeigvec=np.reshape(maxeigvec,(28**2,1))\n",
    "    res1=np.reshape((meanmat[key1]-np.sqrt(max(eigv))*maxeigvec), (28,28))\n",
    "    res2=np.reshape((meanmat[key1]+np.sqrt(max(eigv))*maxeigvec), (28,28))\n",
    "    res3=np.reshape(meanmat[key1], (28,28))\n",
    "    ax[key1][0].imshow(res1)\n",
    "    ax[key1][0].set_title(\"$\\u03BC - v_{1}\\u221A\\u03BB_{1}$\")\n",
    "    ax[key1][1].imshow(res3)\n",
    "    ax[key1][1].set_title(\"\\u03BC\")\n",
    "    ax[key1][2].imshow(res2)\n",
    "    ax[key1][2].set_title(\"$\\u03BC + v_{1}\\u221A\\u03BB_{1}$\")\n",
    "plt.savefig(\"../results/pmv_digit0_2.jpg\",dpi=600)\n",
    "plt.close();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig,ax=plt.subplots(3,3,figsize=(12,12))\n",
    "for key1 in range(3,6):\n",
    "    eigv,eigvect=np.linalg.eigh(covmat[key1])\n",
    "    maxind=np.argmax(eigv)\n",
    "    maxeigvec=eigvect[:,maxind]\n",
    "    maxeigvec=np.reshape(maxeigvec,(28**2,1))\n",
    "    res1=np.reshape((meanmat[key1]-np.sqrt(max(eigv))*maxeigvec), (28,28))\n",
    "    res2=np.reshape((meanmat[key1]+np.sqrt(max(eigv))*maxeigvec), (28,28))\n",
    "    res3=np.reshape(meanmat[key1], (28,28))\n",
    "    ax[key1%3][0].imshow(res1)\n",
    "    ax[key1%3][0].set_title(\"$\\u03BC - v_{1}\\u221A\\u03BB_{1}$\")\n",
    "    ax[key1%3][1].imshow(res3)\n",
    "    ax[key1%3][1].set_title(\"\\u03BC\")\n",
    "    ax[key1%3][2].imshow(res2)\n",
    "    ax[key1%3][2].set_title(\"$\\u03BC + v_{1}\\u221A\\u03BB_{1}$\")\n",
    "plt.savefig(\"../results/pmv_digit3_5.jpg\",dpi=600)\n",
    "plt.close();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig,ax=plt.subplots(4,3,figsize=(12,15))\n",
    "for key1 in range(6,10):\n",
    "    eigv,eigvect=np.linalg.eigh(covmat[key1])\n",
    "    maxind=np.argmax(eigv)\n",
    "    maxeigvec=eigvect[:,maxind]\n",
    "    maxeigvec=np.reshape(maxeigvec,(28**2,1))\n",
    "    res1=np.reshape((meanmat[key1]-np.sqrt(max(eigv))*maxeigvec), (28,28))\n",
    "    res2=np.reshape((meanmat[key1]+np.sqrt(max(eigv))*maxeigvec), (28,28))\n",
    "    res3=np.reshape(meanmat[key1], (28,28))\n",
    "    ax[key1%6][0].imshow(res1)\n",
    "    ax[key1%6][0].set_title(\"$\\u03BC - v_{1}\\u221A\\u03BB_{1}$\")\n",
    "    ax[key1%6][1].imshow(res3)\n",
    "    ax[key1%6][1].set_title(\"\\u03BC\")\n",
    "    ax[key1%6][2].imshow(res2)\n",
    "    ax[key1%6][2].set_title(\"$\\u03BC + v_{1}\\u221A\\u03BB_{1}$\")\n",
    "plt.savefig(\"../results/pmv_digit6_9.jpg\",dpi=600)\n",
    "plt.close();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Q5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "arrays={}\n",
    "mat = h5py.File('../data/mnist.mat') #Process data\n",
    "for k, v in mat.items():\n",
    "    arrays[k] = np.array(v, dtype=np.float64)\n",
    "for i in range(len(arrays['digits_train'])):\n",
    "    arrays['digits_train'][i]=np.transpose(arrays['digits_train'][i])\n",
    "for i in range(len(arrays['digits_test'])):\n",
    "    arrays['digits_test'][i]=np.transpose(arrays['digits_test'][i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reduce_dimensions(digits_train, labels_train): \n",
    "    #Function to find 84 principal eigenvalues and corresponding eigenvectors\n",
    "    digits=[[] for i in range(10)] #Store data of each digit\n",
    "    digit_count=[0 for i in range(10)] #Number of traincases for each digit\n",
    "    for i in range(len(digits_train)):\n",
    "        digit_count[int(labels_train[i])]+=1\n",
    "        digits[int(labels_train[i])].append(digits_train[i])\n",
    "\n",
    "    meanmat=[np.zeros((28*28,1)) for i in range(len(digits))] #Mean vector for each digit\n",
    "\n",
    "    for digit in range(len(digits)): #Compute mean\n",
    "        for i in range(digit_count[digit]):\n",
    "            meanmat[digit]+=np.reshape(digits[digit][i],(28**2,1))\n",
    "        meanmat[digit]/=digit_count[digit]\n",
    "        \n",
    "    covmat=[np.zeros((28*28,28*28)) for i in range(len(digits))] #Covariance matrix for each digit\n",
    "    for digit in range(len(digits)): #Compute covariance matrix\n",
    "        for i in range(digit_count[digit]):\n",
    "            covmat[digit]+=np.matmul(np.reshape(digits[digit][i],(28*28,1)),np.transpose(np.reshape(digits[digit][i],(28*28,1))))\n",
    "        covmat[digit]/=digit_count[digit]\n",
    "        covmat[digit]-=np.matmul(meanmat[digit],np.transpose(meanmat[digit]))\n",
    "    \n",
    "    evecs_all=[] #List of list of eigenvectors of each digit\n",
    "    evalues_all=[] #List of list of eigenvalues of each digit\n",
    "    for i in range(10):\n",
    "        evalues, evecs = np.linalg.eigh(covmat[i]) #Find eigenvalues and eigenvectors for each digit\n",
    "        evec_eval_pair = {evalues[j]:evecs[:,j] for j in range(len(evalues))}\n",
    "        evalues = np.flip(np.sort(evalues)) #Sort eigenvalues\n",
    "        evalues = evalues[0:84] #get top 84 eigenvalues\n",
    "        evecs = np.array([evec_eval_pair[evalue] for evalue in evalues]) #get corresponding eigenvector\n",
    "        evecs_all.append(evecs)\n",
    "        evalues_all.append(evalues)\n",
    "\n",
    "    return (evecs_all, evalues_all, meanmat) #Return tuple of eigenvectors & eigenvalues of all digits and the mean of all digits\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "(evecs, evals, meanmat) = reduce_dimensions(arrays['digits_train'], arrays['labels_train'][0])\n",
    "#Find first 84 principal modes of variation for all digits from 0-9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_coordinates(image, image_label, evecs, m): \n",
    "    return np.matmul(np.transpose(image-m),np.transpose(evecs[image_label]))\n",
    "#Function to reduce dimensionality of each image and compute those 84 co-ordinates\n",
    "#Takes input an image array, label of the image, and top 84 eigenvectors of that corresponding digit\n",
    "#generated from reduce_dimensions function\n",
    "#m denotes mean vector of that digit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "digits_test = arrays['digits_test'] #Test digits raw dataset\n",
    "labels_test = arrays['labels_test'][0] #Labels corresponding to those test digits\n",
    "digits=[[] for i in range(10)] #Test digits dataset sorted according to digits\n",
    "digit_count=[0 for i in range(10)] #Number of testcases for each digit\n",
    "for i in range(len(digits_test)):\n",
    "    digit_count[int(labels_test[i])]+=1 #Increment corresponding digit's count\n",
    "    digits[int(labels_test[i])].append(digits_test[i]) #Add digit data to the corresponding index\n",
    "\n",
    "#Multiple plots for cleaner presentation\n",
    "fig,ax = plt.subplots(3,2,figsize=(10,15))\n",
    "for digit in range(3): #For digits 0-2\n",
    "    coords = compute_coordinates(np.reshape(digits[digit][0],(28*28,1)),digit,evecs, meanmat[digit]) #Reduce dimensionality to 84\n",
    "    reconstructed = np.reshape(np.matmul(coords,evecs[digit])+np.transpose(meanmat[digit]),(28,28)) #Reconstruct image from those 84 dimensions\n",
    "    ax[digit][0].imshow(digits[digit][0]) #Show original image\n",
    "    ax[digit][1].imshow(reconstructed) #Show reconstructed image\n",
    "    ax[digit][0].set_title(f\"Digit {digit} Original image\")\n",
    "    ax[digit][1].set_title(f\"Digit {digit} Reconstructed image\")\n",
    "plt.savefig(\"../results/reconstructimgs0_2.jpg\",dpi=500)\n",
    "plt.close()\n",
    "\n",
    "fig,ax = plt.subplots(3,2,figsize=(10,15))\n",
    "for digit in range(3,6): #For digits 3-5\n",
    "    coords = compute_coordinates(np.reshape(digits[digit][0],(28*28,1)),digit,evecs, meanmat[digit])\n",
    "    reconstructed = np.reshape(np.matmul(coords,evecs[digit])+np.transpose(meanmat[digit]),(28,28))\n",
    "    ax[digit%3][0].imshow(digits[digit][0])\n",
    "    ax[digit%3][1].imshow(reconstructed)\n",
    "    ax[digit%3][0].set_title(f\"Digit {digit} Original image\")\n",
    "    ax[digit%3][1].set_title(f\"Digit {digit} Reconstructed image\")\n",
    "plt.savefig(\"../results/reconstructimgs3_5.jpg\",dpi=500)\n",
    "plt.close()\n",
    "\n",
    "fig,ax = plt.subplots(4,2,figsize=(10,20))\n",
    "for digit in range(6,10): #For digits 6-9\n",
    "    coords = compute_coordinates(np.reshape(digits[digit][0],(28*28,1)),digit,evecs, meanmat[digit])\n",
    "    reconstructed = np.reshape(np.matmul(coords,evecs[digit])+np.transpose(meanmat[digit]),(28,28))\n",
    "    ax[digit%6][0].imshow(digits[digit][0])\n",
    "    ax[digit%6][1].imshow(reconstructed)\n",
    "    ax[digit%6][0].set_title(f\"Digit {digit} Original image\")\n",
    "    ax[digit%6][1].set_title(f\"Digit {digit} Reconstructed image\")\n",
    "plt.savefig(\"../results/reconstructimgs6_9.jpg\",dpi=500)\n",
    "plt.close();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Q6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "from PIL import Image\n",
    "import scipy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "meandat=np.zeros((19200,1)) #Mean vector of fruits\n",
    "dat=[] #Dataset of all fruit images\n",
    "files=Path(\"../data/data_fruit\").glob('*')\n",
    "for file in files:\n",
    "    file_ext=Path(file).suffix\n",
    "    if(file_ext!=\".txt\"):\n",
    "        image=Image.open(file)\n",
    "        az=np.asarray(image)\n",
    "        dat.append(np.reshape(az, (19200,1)))\n",
    "        meandat+=np.reshape(az, (19200,1))\n",
    "meandat/=len(dat) #Computed mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "dat1=[] #Computing covariance\n",
    "files=Path(\"../data/data_fruit\").glob('*')\n",
    "for file in files:\n",
    "    file_ext=Path(file).suffix\n",
    "    if(file_ext!=\".txt\"):\n",
    "        image=Image.open(file) \n",
    "        az=np.asarray(image, dtype=np.float64) #open image and read into an array\n",
    "        az=np.reshape(az,(19200,1)) #reshape the array\n",
    "        az-=meandat #subtract the mean from it\n",
    "        dat1.append(az)\n",
    "dat1=np.reshape(dat1,(16,19200))\n",
    "dat1=np.transpose(dat1)\n",
    "dat1cov=np.matmul(dat1,np.transpose(dat1)) #Compute covariance matrix\n",
    "dat1cov/=(len(dat)-1) #(n-1) for sample covariance estimator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "eigenval,eigenvec=scipy.sparse.linalg.eigsh(dat1cov, k=4, which='LA') #compute top 4 principal eigenvectors & eigenvalues"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig,ax=plt.subplots(1,5, figsize=(15,3)) #Plot the mean & top 4 eigenvector images\n",
    "ax[0].imshow(np.reshape(meandat,(80,80,3))/255)\n",
    "ax[0].set_title(\"Mean Image\")\n",
    "for i in range(4):\n",
    "    acz=np.reshape(eigenvec[:,3-i], (19200,1))\n",
    "    acz=(acz-np.min(acz))/(np.max(acz)-np.min(acz))\n",
    "    ax[i+1].imshow(np.reshape(acz,(80,80,3)))\n",
    "ax[1].set_title(\"$1^{st}$ Principal Eigenvector\")\n",
    "ax[2].set_title(\"$2^{nd}$ Principal Eigenvector\")\n",
    "ax[3].set_title(\"$3^{rd}$ Principal Eigenvector\")\n",
    "ax[4].set_title(\"$4^{th}$ Principal Eigenvector\")\n",
    "plt.savefig(\"../results/4eigv_imgs.jpg\",dpi=900)\n",
    "plt.close();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval10=scipy.sparse.linalg.eigsh(dat1cov, k=10, return_eigenvectors=False, which='LA')\n",
    "#Compute top 10 eigenvalues"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "xs=[i for i in range(1,11)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8,5)) #Plot the top 10 eigenvalues in sorted order\n",
    "plt.plot(xs,np.flip(eval10), 'ro')\n",
    "plt.plot(xs,np.flip(eval10), 'b--', lw=0.5)\n",
    "plt.xlabel(\"Index of eigenvalue\")\n",
    "plt.ylabel(\"Eigenvalue\")\n",
    "plt.title(\"Top 10 Eigenvalues\")\n",
    "plt.savefig(\"../results/top10eig.jpg\",dpi=800)\n",
    "plt.close();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "meandat=meandat.astype(np.float64)\n",
    "distances=[]\n",
    "for i in range(4):\n",
    "    eigenvec[:,i]=eigenvec[:,i]/np.linalg.norm(eigenvec[:,i]) #Normalize top 4 eigenvectors\n",
    "fig,ax=plt.subplots(4,8,figsize=(20,12))\n",
    "for j in range(16):\n",
    "    img = np.reshape(dat[j], (19200,1)).astype(np.float64) #Read images\n",
    "    img-=meandat #Subtract mean from them\n",
    "    img_flattened = np.reshape(img,(19200,1)) #Flatten them into a 19200 dimensional column vector\n",
    "    coords = np.matmul(np.transpose(img_flattened),eigenvec) #Compute coefficients of linear combination\n",
    "    \n",
    "    distances.append(np.linalg.norm(coords))\n",
    "    \n",
    "    #Coefficients are calculated by projecting the image vector onto the eigenvectors and computing the\n",
    "    #directional components\n",
    "    img_reconstructed = np.matmul(coords, np.transpose(eigenvec)) \n",
    "    #Reconstruct the image by adding the linear combination of top 4 eigenvectors to the mean image vector\n",
    "    img_reconstructed = np.reshape(meandat+np.transpose(img_reconstructed),(80,80,3))\n",
    "    img_reconstructed = (img_reconstructed-np.min(img_reconstructed))/(np.max(img_reconstructed)-np.min(img_reconstructed))\n",
    "    ax[j//4][2*(j%4)].imshow(np.reshape(dat[j], (80,80,3))) #Display the original and reconstructed images\n",
    "    ax[j//4][2*(j%4)].set_title(\"Original Image\")\n",
    "    ax[j//4][2*(j%4)+1].set_title(\"Reconstructed Image\")\n",
    "    ax[j//4][2*(j%4)+1].imshow(img_reconstructed)\n",
    "plt.savefig(\"../results/reconstructfruits.jpg\",dpi=400)\n",
    "plt.close();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "meandat = meandat.astype(np.float32)\n",
    "seeds = [25,81,100] # set of seeds used to generate representative images\n",
    "fig,ax=plt.subplots(1,3,figsize=(30,10))\n",
    "for i in range(3):\n",
    "    np.random.seed(seeds[i])\n",
    "    newcoords = np.random.normal(size=(1,4),scale=np.sqrt(eigenval)) # random sample from multivariate gaussian distribution \n",
    "    newimg = np.matmul(newcoords, np.transpose(eigenvec)) # compute the image using the coordinates along principal eigenvectors\n",
    "    newimg = np.reshape(meandat+np.transpose(newimg),(80,80,3))\n",
    "    newimg = (newimg-np.min(newimg))/(np.max(newimg)-np.min(newimg)) #Rescale the sample image\n",
    "    ax[i].imshow(newimg) # display new sampled image\n",
    "    ax[i].set_title(f\"Randomly Sampled Image {i+1}\",size=20)\n",
    "plt.savefig(f\"../results/fruits_random_sample.jpg\",dpi=400)\n",
    "plt.close();"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.7 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "d62f76953c40e0eb0a980b2a0207e2bb7d32bbe99bd995342cf9398946bdf024"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
